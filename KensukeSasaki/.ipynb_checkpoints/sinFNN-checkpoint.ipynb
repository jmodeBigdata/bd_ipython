{
 "metadata": {
  "name": "",
  "signature": "sha256:0fbe83aeffda3ae40f94360064780af45879cc0ad71bf3dc36da2c4bc0a70bcb"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import json, sys, glob, datetime, math\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "import chainer\n",
      "from chainer import computational_graph as c\n",
      "from chainer import cuda\n",
      "import chainer.functions as F\n",
      "from chainer import optimizers\n",
      "%matplotlib inline\n",
      "\n",
      "class RegressionFNN:\n",
      "    def __init__(self, n_units=64, batchsize=100):\n",
      "        self.n_units = n_units\n",
      "        self.batchsize = batchsize\n",
      "        self.plotcount=0\n",
      "\n",
      "    def load(self, train_x, train_y):\n",
      "        if len(train_x)!=len(train_y):\n",
      "            raise ValueError\n",
      "        self.N = len(train_y)\n",
      "        self.I = 1\n",
      "        self.x_train = np.array(train_x, np.float32).reshape(len(train_x),1)\n",
      "        self.y_train = np.array(train_y, np.float32).reshape(len(train_y),)\n",
      "        #\n",
      "        self.model = chainer.FunctionSet(l1=F.Linear(self.I, self.n_units),\n",
      "                                        l2=F.Linear(self.n_units, self.n_units),\n",
      "                                        l3=F.Linear(self.n_units, self.n_units),\n",
      "                                        l4=F.Linear(self.n_units, 1))\n",
      "        #\n",
      "        self.optimizer = optimizers.Adam()\n",
      "        self.optimizer.setup(self.model.collect_parameters())\n",
      "\n",
      "\n",
      "    def forward(self, x_data, y_data, train=True):\n",
      "        x = chainer.Variable(x_data)\n",
      "        t = chainer.Variable(y_data)\n",
      "        h1 = F.relu(self.model.l1(x))\n",
      "        h2 = F.relu(self.model.l2(h1))\n",
      "        h3 = F.relu(self.model.l3(h2))\n",
      "        y = F.reshape(self.model.l4(h3), (len(y_data), ))\n",
      "        return F.mean_squared_error(y, t), y\n",
      "\n",
      "    def calc(self, n_epoch):\n",
      "        for epoch in range(n_epoch):\n",
      "            perm = np.random.permutation(self.N)\n",
      "            sum_loss = 0\n",
      "            #\n",
      "            for i in range(0, self.N, self.batchsize):\n",
      "                x_batch = self.x_train[perm[i:i + self.batchsize]]\n",
      "                y_batch = self.y_train[perm[i:i + self.batchsize]]\n",
      "                #\n",
      "                self.optimizer.zero_grads()\n",
      "                loss, y = self.forward(x_batch, y_batch)\n",
      "                loss.backward()\n",
      "                self.optimizer.update()\n",
      "                #\n",
      "                sum_loss += float(loss.data) * len(y_batch)\n",
      "            #  \n",
      "            print('epoch = {}, train mean loss={}\\r'.format(epoch, sum_loss / self.N), end=\"\")\n",
      "\n",
      "    def getY(self, test_x, test_y):\n",
      "        if len(test_x)!=len(test_y):\n",
      "            raise ValueError\n",
      "        x_test = np.array(test_x, np.float32).reshape(len(test_x),1)\n",
      "        y_test = np.array(test_y, np.float32).reshape(len(test_y),)\n",
      "        loss, y = self.forward(x_test, y_test, train=False)\n",
      "        '''\n",
      "        with open(\"output/{}.csv\".format(self.plotcount), \"w\") as f:\n",
      "            f.write(\"\\n\".join([\"{},{}\".format(ux,uy) for ux,uy in zip(y.data, y_test)]))\n",
      "\n",
      "        #'''\n",
      "        plt.clf()\n",
      "        plt.plot(x_test, y_test, color=\"b\", label=\"original\")\n",
      "        plt.plot(x_test, y.data, color=\"g\", label=\"RegFNN\")\n",
      "        plt.legend(loc = 'lower left')\n",
      "        plt.ylim(-1.2,1.2)\n",
      "        plt.grid(True)\n",
      "        '''\n",
      "        plt.savefig(\"output/{}.png\".format(self.plotcount))\n",
      "        self.plotcount+=1\n",
      "        '''\n",
      "\n",
      "def f(d):\n",
      "    return [math.sin(u) for u in d]\n",
      "if __name__==\"__main__\":\n",
      "    rf = RegressionFNN(n_units=64, batchsize=314)\n",
      "    d = [u*0.02 for u in range(314)]\n",
      "    rf.load(d,f(d))\n",
      "    rf.calc(500) # epoch\n",
      "    rf.getY(d,f(d))\n",
      "    print(\"\\ndone.\")\n",
      "    plt.show()\n",
      "plt.plot(d)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "epoch = 0, train mean loss=1.066690444946289\r",
        "epoch = 1, train mean loss=0.4658149182796478\r",
        "epoch = 2, train mean loss=0.4957011640071869\r",
        "epoch = 3, train mean loss=0.651060938835144\r",
        "epoch = 4, train mean loss=0.646841824054718\r",
        "epoch = 5, train mean loss=0.5385748744010925\r",
        "epoch = 6, train mean loss=0.44216570258140564\r",
        "epoch = 7, train mean loss=0.42070168256759644\r",
        "epoch = 8, train mean loss=0.4629861116409302\r",
        "epoch = 9, train mean loss=0.5083659887313843\r",
        "epoch = 10, train mean loss=0.5119242668151855\r",
        "epoch = 11, train mean loss=0.4754764139652252\r",
        "epoch = 12, train mean loss=0.4296565353870392\r",
        "epoch = 13, train mean loss=0.4040258228778839\r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "epoch = 14, train mean loss=0.40804052352905273\r",
        "epoch = 15, train mean loss=0.4285104274749756\r",
        "epoch = 16, train mean loss=0.44305166602134705\r",
        "epoch = 17, train mean loss=0.43836072087287903\r",
        "epoch = 18, train mean loss=0.4176608920097351\r",
        "epoch = 19, train mean loss=0.3933570981025696\r",
        "epoch = 20, train mean loss=0.38219785690307617\r",
        "epoch = 21, train mean loss=0.3880150318145752\r",
        "epoch = 22, train mean loss=0.3970770239830017\r",
        "epoch = 23, train mean loss=0.3970775306224823\r",
        "epoch = 24, train mean loss=0.38638836145401\r",
        "epoch = 25, train mean loss=0.3755708634853363\r",
        "epoch = 26, train mean loss=0.36825117468833923\r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "epoch = 27, train mean loss=0.36592909693717957\r",
        "epoch = 28, train mean loss=0.36673876643180847\r",
        "epoch = 29, train mean loss=0.3667620122432709\r",
        "epoch = 30, train mean loss=0.3635563552379608\r",
        "epoch = 31, train mean loss=0.3578924238681793\r",
        "epoch = 32, train mean loss=0.3526230454444885\r",
        "epoch = 33, train mean loss=0.34996387362480164\r",
        "epoch = 34, train mean loss=0.34939634799957275\r",
        "epoch = 35, train mean loss=0.3482276201248169\r",
        "epoch = 36, train mean loss=0.3448790907859802\r",
        "epoch = 37, train mean loss=0.34036314487457275\r",
        "epoch = 38, train mean loss=0.33667731285095215\r",
        "epoch = 39, train mean loss=0.33464401960372925\r",
        "epoch = 40, train mean loss=0.3332881033420563\r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "epoch = 41, train mean loss=0.33113497495651245\r",
        "epoch = 42, train mean loss=0.32780835032463074\r",
        "epoch = 43, train mean loss=0.3242206871509552\r",
        "epoch = 44, train mean loss=0.32143640518188477\r",
        "epoch = 45, train mean loss=0.3195345401763916\r",
        "epoch = 46, train mean loss=0.31764310598373413\r",
        "epoch = 47, train mean loss=0.315029114484787\r",
        "epoch = 48, train mean loss=0.3119026720523834\r",
        "epoch = 49, train mean loss=0.30902907252311707\r",
        "epoch = 50, train mean loss=0.3067798614501953\r",
        "epoch = 51, train mean loss=0.3047775328159332\r",
        "epoch = 52, train mean loss=0.30244505405426025\r",
        "epoch = 53, train mean loss=0.2996985912322998\r",
        "epoch = 54, train mean loss=0.29696527123451233\r",
        "epoch = 55, train mean loss=0.294608473777771\r",
        "epoch = 56, train mean loss=0.2925030291080475\r",
        "epoch = 57, train mean loss=0.29025349020957947\r",
        "epoch = 58, train mean loss=0.2877183258533478\r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "epoch = 59, train mean loss=0.28514984250068665\r",
        "epoch = 60, train mean loss=0.2828163504600525\r",
        "epoch = 61, train mean loss=0.2806614637374878\r",
        "epoch = 62, train mean loss=0.2784258723258972\r",
        "epoch = 63, train mean loss=0.2760107219219208\r",
        "epoch = 64, train mean loss=0.273581862449646\r",
        "epoch = 65, train mean loss=0.27131277322769165\r",
        "epoch = 66, train mean loss=0.2691492438316345\r",
        "epoch = 67, train mean loss=0.2669163942337036\r",
        "epoch = 68, train mean loss=0.2645748555660248\r",
        "epoch = 69, train mean loss=0.2622580826282501\r",
        "epoch = 70, train mean loss=0.2600564658641815\r",
        "epoch = 71, train mean loss=0.2578944265842438\r",
        "epoch = 72, train mean loss=0.25566449761390686\r",
        "epoch = 73, train mean loss=0.2533858120441437\r",
        "epoch = 74, train mean loss=0.25115764141082764\r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "epoch = 75, train mean loss=0.24899768829345703\r",
        "epoch = 76, train mean loss=0.2468242347240448\r",
        "epoch = 77, train mean loss=0.24459445476531982\r",
        "epoch = 78, train mean loss=0.2423630803823471\r",
        "epoch = 79, train mean loss=0.24017658829689026\r",
        "epoch = 80, train mean loss=0.23799021542072296\r",
        "epoch = 81, train mean loss=0.23573996126651764\r",
        "epoch = 82, train mean loss=0.2334299236536026\r",
        "epoch = 83, train mean loss=0.23107346892356873\r",
        "epoch = 84, train mean loss=0.22859026491641998\r",
        "epoch = 85, train mean loss=0.22578221559524536\r",
        "epoch = 86, train mean loss=0.2222968488931656\r",
        "epoch = 87, train mean loss=0.2175966501235962\r",
        "epoch = 88, train mean loss=0.21514542400836945\r",
        "epoch = 89, train mean loss=0.21320940554141998\r",
        "epoch = 90, train mean loss=0.2110603004693985\r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "epoch = 91, train mean loss=0.20889116823673248\r",
        "epoch = 92, train mean loss=0.2069362998008728\r",
        "epoch = 93, train mean loss=0.2049640268087387\r",
        "epoch = 94, train mean loss=0.20285353064537048\r",
        "epoch = 95, train mean loss=0.20084989070892334\r",
        "epoch = 96, train mean loss=0.1989632248878479\r",
        "epoch = 97, train mean loss=0.1969788521528244\r",
        "epoch = 98, train mean loss=0.19499051570892334\r",
        "epoch = 99, train mean loss=0.19313929975032806\r",
        "epoch = 100, train mean loss=0.1912730634212494\r",
        "epoch = 101, train mean loss=0.18935644626617432\r",
        "epoch = 102, train mean loss=0.1875447928905487\r",
        "epoch = 103, train mean loss=0.1857706755399704\r",
        "epoch = 104, train mean loss=0.1839495450258255\r",
        "epoch = 105, train mean loss=0.18220147490501404\r",
        "epoch = 106, train mean loss=0.1805097609758377\r",
        "epoch = 107, train mean loss=0.17878757417201996\r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "epoch = 108, train mean loss=0.17712348699569702\r",
        "epoch = 109, train mean loss=0.1755157709121704\r",
        "epoch = 110, train mean loss=0.17389173805713654\r",
        "epoch = 111, train mean loss=0.1723237931728363\r",
        "epoch = 112, train mean loss=0.17080548405647278\r",
        "epoch = 113, train mean loss=0.1692829430103302\r",
        "epoch = 114, train mean loss=0.16781871020793915\r",
        "epoch = 115, train mean loss=0.16639192402362823\r",
        "epoch = 116, train mean loss=0.1649765968322754\r",
        "epoch = 117, train mean loss=0.16362208127975464\r",
        "epoch = 118, train mean loss=0.16228988766670227\r",
        "epoch = 119, train mean loss=0.16098639369010925\r",
        "epoch = 120, train mean loss=0.15973898768424988\r",
        "epoch = 121, train mean loss=0.15850898623466492\r",
        "epoch = 122, train mean loss=0.15732423961162567\r",
        "epoch = 123, train mean loss=0.15617801249027252\r",
        "epoch = 124, train mean loss=0.15505681931972504\r",
        "epoch = 125, train mean loss=0.15398792922496796\r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "epoch = 126, train mean loss=0.15294449031352997\r",
        "epoch = 127, train mean loss=0.1519419401884079\r",
        "epoch = 128, train mean loss=0.15097616612911224\r",
        "epoch = 129, train mean loss=0.15004056692123413\r",
        "epoch = 130, train mean loss=0.14915089309215546\r",
        "epoch = 131, train mean loss=0.14828883111476898\r",
        "epoch = 132, train mean loss=0.1474679857492447\r",
        "epoch = 133, train mean loss=0.1466653048992157\r",
        "epoch = 134, train mean loss=0.14404888451099396\r",
        "epoch = 135, train mean loss=0.14374151825904846\r",
        "epoch = 136, train mean loss=0.14412720501422882\r",
        "epoch = 137, train mean loss=0.1419856995344162\r",
        "epoch = 138, train mean loss=0.13954667747020721\r",
        "epoch = 139, train mean loss=0.14063285291194916\r",
        "epoch = 140, train mean loss=0.13840746879577637\r",
        "epoch = 141, train mean loss=0.13839027285575867\r",
        "epoch = 142, train mean loss=0.13705703616142273\r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "epoch = 143, train mean loss=0.13651056587696075\r",
        "epoch = 144, train mean loss=0.136016383767128\r",
        "epoch = 145, train mean loss=0.13451339304447174\r",
        "epoch = 146, train mean loss=0.13452337682247162\r",
        "epoch = 147, train mean loss=0.13404987752437592\r",
        "epoch = 148, train mean loss=0.13249853253364563\r",
        "epoch = 149, train mean loss=0.13277481496334076\r",
        "epoch = 150, train mean loss=0.13210028409957886\r",
        "epoch = 151, train mean loss=0.13094733655452728\r",
        "epoch = 152, train mean loss=0.13115602731704712\r",
        "epoch = 153, train mean loss=0.13035883009433746\r",
        "epoch = 154, train mean loss=0.12968607246875763\r",
        "epoch = 155, train mean loss=0.12961521744728088\r",
        "epoch = 156, train mean loss=0.12888886034488678\r",
        "epoch = 157, train mean loss=0.12855078279972076\r",
        "epoch = 158, train mean loss=0.1282631754875183\r",
        "epoch = 159, train mean loss=0.12764130532741547\r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "epoch = 160, train mean loss=0.1275244504213333\r",
        "epoch = 161, train mean loss=0.12703727185726166\r",
        "epoch = 162, train mean loss=0.126654714345932\r",
        "epoch = 163, train mean loss=0.12652364373207092\r",
        "epoch = 164, train mean loss=0.12605035305023193\r",
        "epoch = 165, train mean loss=0.12574324011802673\r",
        "epoch = 166, train mean loss=0.12559598684310913\r",
        "epoch = 167, train mean loss=0.12517277896404266\r",
        "epoch = 168, train mean loss=0.12498607486486435\r",
        "epoch = 169, train mean loss=0.12474614381790161\r",
        "epoch = 170, train mean loss=0.12445000559091568\r",
        "epoch = 171, train mean loss=0.12425676733255386\r",
        "epoch = 172, train mean loss=0.1239873468875885\r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "epoch = 173, train mean loss=0.12378989160060883\r",
        "epoch = 174, train mean loss=0.12358085811138153\r",
        "epoch = 175, train mean loss=0.12331283837556839\r",
        "epoch = 176, train mean loss=0.12317405641078949\r",
        "epoch = 177, train mean loss=0.12294623255729675\r",
        "epoch = 178, train mean loss=0.1227247416973114\r",
        "epoch = 179, train mean loss=0.12257450819015503\r",
        "epoch = 180, train mean loss=0.12235573679208755\r",
        "epoch = 181, train mean loss=0.12219267338514328\r",
        "epoch = 182, train mean loss=0.12199919670820236\r",
        "epoch = 183, train mean loss=0.1218106672167778\r",
        "epoch = 184, train mean loss=0.12166435271501541\r",
        "epoch = 185, train mean loss=0.12146246433258057\r",
        "epoch = 186, train mean loss=0.12130700796842575\r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "epoch = 187, train mean loss=0.12114880979061127\r",
        "epoch = 188, train mean loss=0.12096644192934036\r",
        "epoch = 189, train mean loss=0.12080292403697968\r",
        "epoch = 190, train mean loss=0.12062868475914001\r",
        "epoch = 191, train mean loss=0.1204744353890419\r",
        "epoch = 192, train mean loss=0.12030867487192154\r",
        "epoch = 193, train mean loss=0.12013285607099533\r",
        "epoch = 194, train mean loss=0.11998392641544342\r",
        "epoch = 195, train mean loss=0.11981704086065292\r",
        "epoch = 196, train mean loss=0.11965148895978928\r",
        "epoch = 197, train mean loss=0.11949121206998825\r",
        "epoch = 198, train mean loss=0.11932596564292908\r",
        "epoch = 199, train mean loss=0.11916998773813248\r",
        "epoch = 200, train mean loss=0.11900115758180618\r",
        "epoch = 201, train mean loss=0.11883924156427383\r",
        "epoch = 202, train mean loss=0.11868251115083694\r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "epoch = 203, train mean loss=0.1185106411576271\r",
        "epoch = 204, train mean loss=0.11834868788719177\r",
        "epoch = 205, train mean loss=0.11818186938762665\r",
        "epoch = 206, train mean loss=0.11801804602146149\r",
        "epoch = 207, train mean loss=0.11785129457712173\r",
        "epoch = 208, train mean loss=0.1176799014210701\r",
        "epoch = 209, train mean loss=0.11751483380794525\r",
        "epoch = 210, train mean loss=0.11734522879123688\r",
        "epoch = 211, train mean loss=0.11717676371335983\r",
        "epoch = 212, train mean loss=0.11700364202260971\r",
        "epoch = 213, train mean loss=0.11683265119791031\r",
        "epoch = 214, train mean loss=0.11666149646043777\r",
        "epoch = 215, train mean loss=0.11648586392402649\r",
        "epoch = 216, train mean loss=0.11631191521883011\r",
        "epoch = 217, train mean loss=0.11613653600215912\r",
        "epoch = 218, train mean loss=0.11595922708511353\r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "epoch = 219, train mean loss=0.11578060686588287\r",
        "epoch = 220, train mean loss=0.11560089141130447\r",
        "epoch = 221, train mean loss=0.11542230099439621\r",
        "epoch = 222, train mean loss=0.11524024605751038\r",
        "epoch = 223, train mean loss=0.11505893617868423\r",
        "epoch = 224, train mean loss=0.11487706750631332\r",
        "epoch = 225, train mean loss=0.11469542235136032\r",
        "epoch = 226, train mean loss=0.1145111620426178\r",
        "epoch = 227, train mean loss=0.114324651658535\r",
        "epoch = 228, train mean loss=0.11413967609405518\r",
        "epoch = 229, train mean loss=0.11394541710615158\r",
        "epoch = 230, train mean loss=0.11375436931848526\r",
        "epoch = 231, train mean loss=0.11356555670499802\r",
        "epoch = 232, train mean loss=0.11337544769048691\r",
        "epoch = 233, train mean loss=0.11318247765302658\r",
        "epoch = 234, train mean loss=0.11298734694719315\r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "epoch = 235, train mean loss=0.11279108375310898\r",
        "epoch = 236, train mean loss=0.11259820312261581\r",
        "epoch = 237, train mean loss=0.11240331083536148\r",
        "epoch = 238, train mean loss=0.11220624297857285\r",
        "epoch = 239, train mean loss=0.1120036393404007\r",
        "epoch = 240, train mean loss=0.11180321127176285\r",
        "epoch = 241, train mean loss=0.11160138249397278\r",
        "epoch = 242, train mean loss=0.11140041053295135\r",
        "epoch = 243, train mean loss=0.11119923740625381\r",
        "epoch = 244, train mean loss=0.11099497973918915\r",
        "epoch = 245, train mean loss=0.1107896938920021\r",
        "epoch = 246, train mean loss=0.11058372259140015\r",
        "epoch = 247, train mean loss=0.1103772446513176\r",
        "epoch = 248, train mean loss=0.11016882210969925\r",
        "epoch = 249, train mean loss=0.10995988547801971\r",
        "epoch = 250, train mean loss=0.10975011438131332\r",
        "epoch = 251, train mean loss=0.10954148322343826\r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "epoch = 252, train mean loss=0.10932912677526474\r",
        "epoch = 253, train mean loss=0.10911579430103302\r",
        "epoch = 254, train mean loss=0.10890282690525055\r",
        "epoch = 255, train mean loss=0.10868837684392929\r",
        "epoch = 256, train mean loss=0.10847310721874237\r",
        "epoch = 257, train mean loss=0.10825753957033157\r",
        "epoch = 258, train mean loss=0.10804039239883423\r",
        "epoch = 259, train mean loss=0.10782328248023987\r",
        "epoch = 260, train mean loss=0.1076047345995903\r",
        "epoch = 261, train mean loss=0.1073857918381691\r",
        "epoch = 262, train mean loss=0.10716626793146133\r",
        "epoch = 263, train mean loss=0.10694615542888641\r",
        "epoch = 264, train mean loss=0.10672709345817566\r",
        "epoch = 265, train mean loss=0.10650979727506638\r",
        "epoch = 266, train mean loss=0.10629058629274368\r",
        "epoch = 267, train mean loss=0.1060706302523613\r",
        "epoch = 268, train mean loss=0.10583345592021942\r",
        "epoch = 269, train mean loss=0.10560586303472519\r",
        "epoch = 270, train mean loss=0.10538575053215027\r",
        "epoch = 271, train mean loss=0.10515887290239334\r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "epoch = 272, train mean loss=0.10492758452892303\r",
        "epoch = 273, train mean loss=0.1046980619430542\r",
        "epoch = 274, train mean loss=0.10447388142347336\r",
        "epoch = 275, train mean loss=0.10424675047397614\r",
        "epoch = 276, train mean loss=0.10401012748479843\r",
        "epoch = 277, train mean loss=0.10378126800060272\r",
        "epoch = 278, train mean loss=0.10355506092309952\r",
        "epoch = 279, train mean loss=0.10332003235816956\r",
        "epoch = 280, train mean loss=0.10308589786291122\r",
        "epoch = 281, train mean loss=0.10285291075706482\r",
        "epoch = 282, train mean loss=0.10262046009302139\r",
        "epoch = 283, train mean loss=0.10238947719335556\r",
        "epoch = 284, train mean loss=0.10215236991643906\r",
        "epoch = 285, train mean loss=0.10191593319177628\r",
        "epoch = 286, train mean loss=0.10168132930994034\r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "epoch = 287, train mean loss=0.10144613683223724\r",
        "epoch = 288, train mean loss=0.10121192783117294\r",
        "epoch = 289, train mean loss=0.10097360610961914\r",
        "epoch = 290, train mean loss=0.10073592513799667\r",
        "epoch = 291, train mean loss=0.10049767792224884\r",
        "epoch = 292, train mean loss=0.10026003420352936\r",
        "epoch = 293, train mean loss=0.1000228300690651\r",
        "epoch = 294, train mean loss=0.0997837483882904\r",
        "epoch = 295, train mean loss=0.09954461455345154\r",
        "epoch = 296, train mean loss=0.09930414706468582\r",
        "epoch = 297, train mean loss=0.09906306862831116\r",
        "epoch = 298, train mean loss=0.09874678403139114\r",
        "epoch = 299, train mean loss=0.0972864106297493\r",
        "epoch = 300, train mean loss=0.09596502780914307\r",
        "epoch = 301, train mean loss=0.09616504609584808\r",
        "epoch = 302, train mean loss=0.09626688063144684\r",
        "epoch = 303, train mean loss=0.09620529413223267\r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "epoch = 304, train mean loss=0.096086785197258\r",
        "epoch = 305, train mean loss=0.09588713198900223\r",
        "epoch = 306, train mean loss=0.095690056681633\r",
        "epoch = 307, train mean loss=0.0954611673951149\r",
        "epoch = 308, train mean loss=0.09524013102054596\r",
        "epoch = 309, train mean loss=0.09499768912792206\r",
        "epoch = 310, train mean loss=0.09477029740810394\r",
        "epoch = 311, train mean loss=0.09452840685844421\r",
        "epoch = 312, train mean loss=0.09428868442773819\r",
        "epoch = 313, train mean loss=0.09406110644340515\r",
        "epoch = 314, train mean loss=0.09385640174150467\r",
        "epoch = 315, train mean loss=0.093626469373703\r",
        "epoch = 316, train mean loss=0.09337332099676132\r",
        "epoch = 317, train mean loss=0.09309016913175583\r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "epoch = 318, train mean loss=0.09290890395641327\r",
        "epoch = 319, train mean loss=0.09263528138399124\r",
        "epoch = 320, train mean loss=0.09238957613706589\r",
        "epoch = 321, train mean loss=0.09217382222414017\r",
        "epoch = 322, train mean loss=0.09189143031835556\r",
        "epoch = 323, train mean loss=0.09168381989002228\r",
        "epoch = 324, train mean loss=0.09141285717487335\r",
        "epoch = 325, train mean loss=0.09120488166809082\r",
        "epoch = 326, train mean loss=0.09095203131437302\r",
        "epoch = 327, train mean loss=0.0907125398516655\r",
        "epoch = 328, train mean loss=0.09048647433519363\r",
        "epoch = 329, train mean loss=0.09022970497608185\r",
        "epoch = 330, train mean loss=0.09001140296459198\r",
        "epoch = 331, train mean loss=0.08975789695978165\r",
        "epoch = 332, train mean loss=0.08953952044248581\r",
        "epoch = 333, train mean loss=0.08929456025362015\r",
        "epoch = 334, train mean loss=0.08906268328428268\r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "epoch = 335, train mean loss=0.08883137255907059\r",
        "epoch = 336, train mean loss=0.08859024941921234\r",
        "epoch = 337, train mean loss=0.08836724609136581\r",
        "epoch = 338, train mean loss=0.08812303841114044\r",
        "epoch = 339, train mean loss=0.0879029929637909\r",
        "epoch = 340, train mean loss=0.08766058832406998\r",
        "epoch = 341, train mean loss=0.08743211627006531\r",
        "epoch = 342, train mean loss=0.08719761669635773\r",
        "epoch = 343, train mean loss=0.08696034550666809\r",
        "epoch = 344, train mean loss=0.08673179894685745\r",
        "epoch = 345, train mean loss=0.08648890256881714\r",
        "epoch = 346, train mean loss=0.08625681698322296\r",
        "epoch = 347, train mean loss=0.08601219952106476\r",
        "epoch = 348, train mean loss=0.08576840162277222\r",
        "epoch = 349, train mean loss=0.08551694452762604\r",
        "epoch = 350, train mean loss=0.08525600284337997\r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "epoch = 351, train mean loss=0.08498311787843704\r",
        "epoch = 352, train mean loss=0.0846870169043541\r",
        "epoch = 353, train mean loss=0.08436361700296402\r",
        "epoch = 354, train mean loss=0.0840187594294548\r",
        "epoch = 355, train mean loss=0.08367200195789337\r",
        "epoch = 356, train mean loss=0.08344960957765579\r",
        "epoch = 357, train mean loss=0.08344549685716629\r",
        "epoch = 358, train mean loss=0.08322973549365997\r",
        "epoch = 359, train mean loss=0.08280906826257706\r",
        "epoch = 360, train mean loss=0.08256349712610245\r",
        "epoch = 361, train mean loss=0.08240669220685959\r",
        "epoch = 362, train mean loss=0.08224662393331528\r",
        "epoch = 363, train mean loss=0.08205617964267731\r",
        "epoch = 364, train mean loss=0.08183366060256958\r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "epoch = 365, train mean loss=0.08158755302429199\r",
        "epoch = 366, train mean loss=0.08132302016019821\r",
        "epoch = 367, train mean loss=0.08105605095624924\r",
        "epoch = 368, train mean loss=0.08082961291074753\r",
        "epoch = 369, train mean loss=0.08065392822027206\r",
        "epoch = 370, train mean loss=0.08047951757907867\r",
        "epoch = 371, train mean loss=0.08022484928369522\r",
        "epoch = 372, train mean loss=0.0799703598022461\r",
        "epoch = 373, train mean loss=0.0797564908862114\r",
        "epoch = 374, train mean loss=0.07956434041261673\r",
        "epoch = 375, train mean loss=0.07936561852693558\r",
        "epoch = 376, train mean loss=0.07915531098842621\r",
        "epoch = 377, train mean loss=0.07893078029155731\r",
        "epoch = 378, train mean loss=0.07870019227266312\r",
        "epoch = 379, train mean loss=0.07847405225038528\r",
        "epoch = 380, train mean loss=0.07826302200555801\r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "epoch = 381, train mean loss=0.07806721329689026\r",
        "epoch = 382, train mean loss=0.07786111533641815\r",
        "epoch = 383, train mean loss=0.07764013856649399\r",
        "epoch = 384, train mean loss=0.07741679251194\r",
        "epoch = 385, train mean loss=0.07720483094453812\r",
        "epoch = 386, train mean loss=0.07699941098690033\r",
        "epoch = 387, train mean loss=0.07679494470357895\r",
        "epoch = 388, train mean loss=0.07658471167087555\r",
        "epoch = 389, train mean loss=0.07637199759483337\r",
        "epoch = 390, train mean loss=0.0761570930480957\r",
        "epoch = 391, train mean loss=0.07594482600688934\r",
        "epoch = 392, train mean loss=0.07573600113391876\r",
        "epoch = 393, train mean loss=0.07553092390298843\r",
        "epoch = 394, train mean loss=0.07532479614019394\r",
        "epoch = 395, train mean loss=0.07511521875858307\r",
        "epoch = 396, train mean loss=0.07490421831607819\r",
        "epoch = 397, train mean loss=0.07469485700130463\r",
        "epoch = 398, train mean loss=0.07448768615722656\r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "epoch = 399, train mean loss=0.07428169250488281\r",
        "epoch = 400, train mean loss=0.0740765631198883\r",
        "epoch = 401, train mean loss=0.073868028819561\r",
        "epoch = 402, train mean loss=0.07365980744361877\r",
        "epoch = 403, train mean loss=0.07345113158226013\r",
        "epoch = 404, train mean loss=0.07324536889791489\r",
        "epoch = 405, train mean loss=0.07303927838802338\r",
        "epoch = 406, train mean loss=0.0728343054652214\r",
        "epoch = 407, train mean loss=0.07262855023145676\r",
        "epoch = 408, train mean loss=0.07242260873317719\r",
        "epoch = 409, train mean loss=0.07221656292676926\r",
        "epoch = 410, train mean loss=0.07201129198074341\r",
        "epoch = 411, train mean loss=0.07180722802877426\r",
        "epoch = 412, train mean loss=0.07160351425409317\r",
        "epoch = 413, train mean loss=0.07139977812767029\r",
        "epoch = 414, train mean loss=0.07119637727737427\r",
        "epoch = 415, train mean loss=0.07099291682243347\r",
        "epoch = 416, train mean loss=0.07079139351844788\r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "epoch = 417, train mean loss=0.07059331983327866\r",
        "epoch = 418, train mean loss=0.07039247453212738\r",
        "epoch = 419, train mean loss=0.07019557803869247\r",
        "epoch = 420, train mean loss=0.06998535990715027\r",
        "epoch = 421, train mean loss=0.0697731003165245\r",
        "epoch = 422, train mean loss=0.06956542283296585\r",
        "epoch = 423, train mean loss=0.06936496496200562\r",
        "epoch = 424, train mean loss=0.06916964799165726\r",
        "epoch = 425, train mean loss=0.06896631419658661\r",
        "epoch = 426, train mean loss=0.068759486079216\r",
        "epoch = 427, train mean loss=0.06855285912752151\r",
        "epoch = 428, train mean loss=0.06835096329450607\r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "epoch = 429, train mean loss=0.06814999133348465\r",
        "epoch = 430, train mean loss=0.06794881075620651\r",
        "epoch = 431, train mean loss=0.06774723529815674\r",
        "epoch = 432, train mean loss=0.06754300743341446\r",
        "epoch = 433, train mean loss=0.0673406571149826\r",
        "epoch = 434, train mean loss=0.0671396553516388\r",
        "epoch = 435, train mean loss=0.06694021075963974\r",
        "epoch = 436, train mean loss=0.06674200296401978\r",
        "epoch = 437, train mean loss=0.0665392205119133\r",
        "epoch = 438, train mean loss=0.06633783131837845\r",
        "epoch = 439, train mean loss=0.0661332905292511\r",
        "epoch = 440, train mean loss=0.06593264639377594\r",
        "epoch = 441, train mean loss=0.06573162227869034\r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "epoch = 442, train mean loss=0.06553275138139725\r",
        "epoch = 443, train mean loss=0.06533224135637283\r",
        "epoch = 444, train mean loss=0.06513158231973648\r",
        "epoch = 445, train mean loss=0.06492961943149567\r",
        "epoch = 446, train mean loss=0.06472793221473694\r",
        "epoch = 447, train mean loss=0.06452612578868866\r",
        "epoch = 448, train mean loss=0.0643252581357956\r",
        "epoch = 449, train mean loss=0.0641244500875473\r",
        "epoch = 450, train mean loss=0.06392428278923035\r",
        "epoch = 451, train mean loss=0.0637240931391716\r",
        "epoch = 452, train mean loss=0.06352417916059494\r",
        "epoch = 453, train mean loss=0.06332433968782425\r",
        "epoch = 454, train mean loss=0.06312547624111176\r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "epoch = 455, train mean loss=0.06292650103569031\r",
        "epoch = 456, train mean loss=0.06273001432418823\r",
        "epoch = 457, train mean loss=0.06253281980752945\r",
        "epoch = 458, train mean loss=0.06233952194452286\r",
        "epoch = 459, train mean loss=0.06213546544313431\r",
        "epoch = 460, train mean loss=0.06192987412214279\r",
        "epoch = 461, train mean loss=0.0617167167365551\r",
        "epoch = 462, train mean loss=0.06151002645492554\r",
        "epoch = 463, train mean loss=0.06131182983517647\r",
        "epoch = 464, train mean loss=0.061115436255931854\r",
        "epoch = 465, train mean loss=0.06091659516096115\r",
        "epoch = 466, train mean loss=0.06071184203028679\r",
        "epoch = 467, train mean loss=0.06050346791744232\r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "epoch = 468, train mean loss=0.060299962759017944\r",
        "epoch = 469, train mean loss=0.060100313276052475\r",
        "epoch = 470, train mean loss=0.059905484318733215\r",
        "epoch = 471, train mean loss=0.05970205366611481\r",
        "epoch = 472, train mean loss=0.05949752777814865\r",
        "epoch = 473, train mean loss=0.05928698554635048\r",
        "epoch = 474, train mean loss=0.05908387899398804\r",
        "epoch = 475, train mean loss=0.05888568237423897\r",
        "epoch = 476, train mean loss=0.05868690088391304\r",
        "epoch = 477, train mean loss=0.05848313122987747\r",
        "epoch = 478, train mean loss=0.05827182158827782\r",
        "epoch = 479, train mean loss=0.05806489288806915\r",
        "epoch = 480, train mean loss=0.0578625313937664\r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "epoch = 481, train mean loss=0.057661984115839005\r",
        "epoch = 482, train mean loss=0.057457491755485535\r",
        "epoch = 483, train mean loss=0.057248618453741074\r",
        "epoch = 484, train mean loss=0.05703945457935333\r",
        "epoch = 485, train mean loss=0.056834377348423004\r",
        "epoch = 486, train mean loss=0.056629981845617294\r",
        "epoch = 487, train mean loss=0.05642620101571083\r",
        "epoch = 488, train mean loss=0.05621888116002083\r",
        "epoch = 489, train mean loss=0.056010834872722626\r",
        "epoch = 490, train mean loss=0.055800601840019226\r",
        "epoch = 491, train mean loss=0.05559244751930237\r",
        "epoch = 492, train mean loss=0.05538537725806236\r",
        "epoch = 493, train mean loss=0.055176667869091034\r",
        "epoch = 494, train mean loss=0.05496973171830177\r",
        "epoch = 495, train mean loss=0.05476036295294762\r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "epoch = 496, train mean loss=0.05455183610320091\r",
        "epoch = 497, train mean loss=0.054341401904821396\r",
        "epoch = 498, train mean loss=0.05413202941417694\r",
        "epoch = 499, train mean loss=0.05392032116651535\r\n",
        "done."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD7CAYAAABpJS8eAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
       "text": [
        "<matplotlib.figure.Figure at 0x177516b6908>"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "[<matplotlib.lines.Line2D at 0x17752661d30>]"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAXEAAAEACAYAAABF+UbAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
       "text": [
        "<matplotlib.figure.Figure at 0x1775169cbe0>"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}