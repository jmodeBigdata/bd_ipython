{
 "metadata": {
  "name": "",
  "signature": "sha256:0d51eb59950334b0fbf03ab63cd75f55a651e3dd1758d8ab8949330968ecbc53"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#!/usr/bin/env python\n",
      "# coding: utf-8\n",
      "import pandas as pd\n",
      "temp=pd.read_csv(\"Univ2.csv\",header=None)\n",
      "temptarget = pd.read_csv(\"Univ3.csv\",header=None)\n",
      "\n",
      "\n",
      "#from __future__ import print_function\n",
      "import numpy as np\n",
      "from sklearn.cross_validation import train_test_split\n",
      "\n",
      "import six\n",
      "import sys\n",
      "import chainer\n",
      "import chainer.links as L\n",
      "from chainer import optimizers\n",
      "import chainer.functions as F\n",
      "from matplotlib import pyplot\n",
      "#%matplotlib inline\n",
      "\n",
      "\n",
      "batchsize = 40\n",
      "n_epoch = 20\n",
      "\n",
      "# Prepare dataset\n",
      "target_list=[]\n",
      "for i in zip(temptarget[0]):\n",
      "    target_list.append(i)\n",
      "target = np.array(target_list)\n",
      "\n",
      "feature_lists = []\n",
      "for i,j in zip(temp[0],temp[1]):\n",
      "    feature_lists.append([i,j])\n",
      "features = np.array(feature_lists)\n",
      "\n",
      "target=target.astype(np.float32).reshape(len(target_list), 1)\n",
      "feature=features.astype(np.float32)\n",
      "\n",
      "x_train, x_test, y_train, y_test = train_test_split(feature, target, test_size=0.15)\n",
      "N_test = y_test.size  # test data size\n",
      "N = len(x_train)  # train data size\n",
      "in_units = x_train.shape[1]  \n",
      "\n",
      "\n",
      "n_units_2 = 90\n",
      "n_units_3 = 50\n",
      "n_units_4 = 30\n",
      "n_units_5 = 10\n",
      "\n",
      "model = chainer.Chain(\n",
      "    l1=L.Linear(in_units, n_units_2),\n",
      "    l2=L.Linear(n_units_2, n_units_3),\n",
      "    l3=L.Linear(n_units_3,  n_units_4),\n",
      "    l4=L.Linear(n_units_4,  n_units_5),\n",
      "    l5=L.Linear(n_units_5,  1))\n",
      "\n",
      "'''\n",
      "def forward(x):\n",
      "    h1 = F.relu(model.l1(x))\n",
      "    h2 = F.relu(model.l2(h1))\n",
      "    h3 = F.relu(model.l3(h2))\n",
      "    h4 = F.relu(model.l4(h3))\n",
      "    return F.tanh(model.l5(h4))\n",
      "'''\n",
      "\n",
      "def forward(x_data, y_data, train=True):\n",
      "        x = chainer.Variable(x_data)\n",
      "        t = chainer.Variable(y_data)\n",
      "        h1 = F.relu(model.l1(x))\n",
      "        h2 = F.relu(model.l2(h1))\n",
      "        h3 = F.relu(model.l3(h2))\n",
      "        h4 = F.relu(model.l4(h3))\n",
      "        y = F.reshape(model.l5(h4), (len(y_data), ))\n",
      "        return F.mean_squared_error(y, t), y\n",
      "\n",
      "# Setup optimizer\u6700\u9069\u5316\u306e\u30bb\u30c3\u30c8\u30a2\u30c3\u30d7\n",
      "optimizer = optimizers.Adam()#\u52fe\u914d\u6cd5\u306e\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0:Adam\n",
      "optimizer.setup(model)\n",
      "#optimizer.add_hokk(optimizer.WeightDecay())#\u6b63\u5247\u5316\u3092hook\u95a2\u6570\u3068\u3057\u3066\u767b\u9332\n",
      "\n",
      "# Learning loop\n",
      "LOSS = []\n",
      "for epoch in six.moves.range(1, n_epoch + 1):\n",
      "    print('epoch', epoch)\n",
      "    # training\n",
      "    perm = np.random.permutation(N)\n",
      "    sum_loss = 0.0\n",
      "    for i in six.moves.range(0, N, batchsize):\n",
      "        x = chainer.Variable(np.asarray(x_train[perm[i:i + batchsize]]))\n",
      "        t = chainer.Variable(np.asarray(y_train[perm[i:i + batchsize]]))\n",
      "        model.zerograds()#\u52fe\u914d\u3092\u30bc\u30ed\u521d\u671f\u5316\n",
      "        y = forward(x,t)\n",
      "        loss = F.mean_squared_error(y, t)#\u5e73\u57472\u4e57\u8aa4\u5dee\n",
      "        sum_loss += loss.data\n",
      "        loss.backward()#\u52fe\u914d\u8a08\u7b97\n",
      "        optimizer.update()#\u6700\u9069\u5316\u30eb\u30fc\u30c1\u30f3\u3092\u5b9f\u884c\n",
      "    print('train mean loss={}'.format(sum_loss / N))\n",
      "\n",
      "    # all test data\n",
      "    x = chainer.Variable(np.asarray(x_test))\n",
      "    t = chainer.Variable(np.asarray(y_test))\n",
      "    y = forward(x,t)\n",
      "    loss = F.mean_squared_error(y, t)\n",
      "    LOSS.append(loss.data/N_test)\n",
      "    print(' test mean loss={}'.format(loss.data / N_test))\n",
      "print(LOSS)\n",
      "pyplot.plot(LOSS)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "epoch 1\n"
       ]
      },
      {
       "ename": "TypeError",
       "evalue": "numpy.ndarray or cuda.ndarray are expected.\nActual: <class 'chainer.variable.Variable'>",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-4-8bc9db61549b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     90\u001b[0m         \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mchainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mperm\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mbatchsize\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzerograds\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#\u52fe\u914d\u3092\u30bc\u30ed\u521d\u671f\u5316\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#\u5e73\u57472\u4e57\u8aa4\u5dee\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m         \u001b[0msum_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m<ipython-input-4-8bc9db61549b>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(x_data, y_data, train)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mchainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m         \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mchainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m         \u001b[0mh1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ml1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Users\\Kensuke\\PythonPrac\\chainer\\variable.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, volatile, name)\u001b[0m\n\u001b[0;32m     91\u001b[0m             msg = '''numpy.ndarray or cuda.ndarray are expected.\n\u001b[0;32m     92\u001b[0m Actual: {0}'''.format(type(data))\n\u001b[1;32m---> 93\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mTypeError\u001b[0m: numpy.ndarray or cuda.ndarray are expected.\nActual: <class 'chainer.variable.Variable'>"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}